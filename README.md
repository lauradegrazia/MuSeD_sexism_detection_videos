# MuSeD: A Multimodal Spanish Dataset for Sexism Detection

MuSeD is a new Multimodal Spanish dataset for Sexism Detection on social media videos. Content is considered sexist in four main cases:
* Stereotype: It attributes a set of properties that supposedly differentiate men and women, based on stereotypical beliefs;
* Inequality: It asserts that gender inequalities no longer exist that the feminist movement is marginalizing the position of men in society;
* Discrimination: It discriminates against the LGBTQ+ community:
* Objectification: It portrays women as physical objects, often hypersexualizing their bodies;

The following figure illustrates a sexist video that includes a gender stereotype:

<img width="255" alt="stereotype" src="https://github.com/user-attachments/assets/289dbe15-ea76-470e-a331-5309eb1c6b6c" />


## Human annotation
MuSeD was annotated by a team of six annotators with diverse gender and age backgrounds to mitigate demographic bias. Our annotation process consisted of three
levels: first, annotators labeled the transcript and the OCR texts; second, they annotated the audio; and finally, they annotated the entire video, which included all the modalities.

## Dataset statistics 
MuSeD includes 400 videos, â‰ˆ 11 hours, extracted from two different platforms as data sources: TikTok, a moderated platform, and BitChute, a low-moderation platform, which enables us to find diverse material. The following figure illustrates the dataset statistics:

<img width="394" alt="Screenshot 2025-04-09 at 15 28 48" src="https://github.com/user-attachments/assets/49cb9f40-a411-47eb-b900-3b31e26645df" />


## Model evaluation 
